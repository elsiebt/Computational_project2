---
title: "TMA4300 Computer Intensive Statistical Methods"
subtitle: "Exercise 2"
author: "Maja B. Mathiassen & Elsie B. Tandberg"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(boot)
library(ggplot2)
library(invgamma)
```

# Problem A: The coal mining disaster data
In this problem we look at a data set of mining disasters in the UK, from March 15th 1951 to March 22nd 1962.

## A1

To get an impression of the data set, we make a plot of the cumulative number of disasters as a function of time. 
```{r A1, fig.cap="Caption"}
#The x-axis contains the specific time of an accident
x <- coal$date

#y is the cumulative sum of disasters
y <- rep(1,length(x))
y[1]<-0
y <- cumsum(y)
y[length(x)]<-0

#Plotting
ggplot()+
  geom_line(aes(x=x[1:190],y=y[1:190])) +
  xlab('Time') + ylab('Cumulative number of disasters') + 
  ggtitle('Mining disasters') 
```
From the figure above we can see that ..... etc. 

## A2

We denote the starting time of the observations as $t_0$ and the end time as $t_2$. We assume the coal mining disasters follow an inhomogeneous Poisson process with intensity function

$$
\begin{aligned}
\lambda(t)=\begin{cases}
\lambda_0, \quad t\in[t_0, t_1), \\
\lambda_1, \quad t\in[t_1, t_2],
\end{cases}
\end{aligned}
$$ 

where $t_1\in(t_0, t_2)$. The likelihood function for the observed data becomes

$$
\begin{aligned}
f(x|t_1,\lambda_0,\lambda_1) = \exp\{-\lambda_0(t_1-t_0)-\lambda_1(t_2-t_1)\}\lambda_0^{y_0}\lambda_1^{y_1},
\end{aligned}
$$

where $y_0$ is the number of mining disasters from $t_0$ to $t_1$, and $y_1$ is the number of disasters from $t_1$ to $t_2$. We assume $t_1\sim\text{Unif}(t_0,t_2)$ and that $t_1$, $\lambda_0$ and $\lambda_1$ all are apriori independent of each other. 

We use a gamma distributed prior for $\lambda_0$ and $\lambda_1$, with $\alpha=2$ and scale parameter $\beta$. Then

$$
\begin{aligned}
f(\lambda_i|\beta)=\frac{1}{\beta^2}\lambda_i\exp\{-\frac{\lambda_0}{\beta}\}, \quad i=0,1.
\end{aligned}
$$

For $\beta$, we use the improper prior 

$$
\begin{aligned}
f(\beta)\propto\frac{\exp\{-1/\beta\}}{\beta},
\end{aligned}
$$

for some $\beta>0$.

The parameters in our model are $\theta=(t_1,\lambda_0,\lambda_1,\beta)$. The posterior distribution of $\theta$ is given by

$$
\begin{aligned}
f(\theta|x)&=f(x|t_1, \lambda_0, \lambda_1,\beta)f(t_1)f(\lambda_0|\beta)f(\lambda_1|\beta)f(\beta)\\
&\propto\exp\{-\lambda_0(t_1-t_0)-\lambda_1(t_2-t_1)\}\lambda_0^{y_0}\lambda_1^{y_1}\frac{1}{\beta^5}\lambda_0\lambda_1\exp\{-\frac{1}{\beta}(\lambda_0+\lambda_1)-\frac{1}{\beta}\}.
\end{aligned}
$$

## A3
The full conditionals are

$$
\begin{aligned}
f(t_1|...) &\propto \exp\{-t_1(\lambda_0-\lambda_1)\}\lambda_0^{y_0}\lambda_1^{y_1} \\
f(\lambda_0|...) &\propto \lambda_0^{y_0+1} \exp\{-\lambda_0(\frac{1}{\beta} +t_1-t_0)\} \\
f(\lambda_1|...) &\propto \lambda_1^{y_1+1} \exp\{-\lambda_1(\frac{1}{\beta} +t_2-t_1)\} \\
f(\beta|...) &\propto \frac{1}{\beta^5}\exp\{\frac{1}{\beta}(1+\lambda_0+\lambda_1)\}
\end{aligned}
$$


From this we can see that $f(t_1|...)$ does not belong to a distribution. Next $f(\lambda_0|...)\sim\text{Gamma}(\alpha_0,\beta_0)$ when $\alpha_0=y_0+2$ and $\beta_0^{-1}=1/\beta + t_1 - t_0$, and $f(\lambda_1|...)\sim\text{Gamma}(\alpha_1,\beta_1)$ when $\alpha_1=y_1+2$ and $\beta_1^{-1}=1/\beta + t_2 - t_1$. Lastly $f(\beta|...)\sim \text{invGamma}(4, 1+\lambda_0 + \lambda_1)$.

## A4

We want to implement a single site MCMC algorithm for $f(\theta|x)$. Since $\lambda_0$, $\lambda_1$, and $\beta$ are from known distributions we can use Gibbs sampling for these variables. For $t_1$ we choose to use random walk, and 
$$
\begin{aligned}
t_1^{i}\sim \mathcal{N}(t_1^{i-1}, \sigma^2),
\end{aligned}
$$
where $t_1^{i-1}$ is the current value and $t_1^i$ is the proposed new value. The acceptance probability becomes
$$
\begin{aligned}
\alpha = \min\bigg(1, \frac{f(t_1^i|...)}{f(t_1^{i-1}|...)}\bigg) = \min\Big(1, \exp\{(t_1^{i-1}-t_1^i)(\lambda_0-\lambda_1)\}\lambda_0\lambda_1\Big)
\end{aligned}
$$
maybe... I am not entirely sure...

```{r}
find_y0_y1 = function(t0, t1, t2) {
  if (coal$date[190] < t1) { # If t1 is after the last disaster 
    y0 = 189        
  } else { # Find out how many disasters happened before t1
    y0 = 0
    i = 2
    done = FALSE
    while (done == F) {
      if (coal$date[i] < t1) {
        i = i+1
      } else {
        done = TRUE
        i = i-1
      }
    }
    y0 = coal$cumulative[i]
  }
  y1 = 189 - y0 # How many disasters happened after t1
  return( c(y0,y1) )
}
```


```{r}
#Trying to make the algortihm
theta0 <- c(1900, 1, 1, 3)
t0 <- 1851
t2 <- 1962
MCMC <- function(theta, n){
  t1 <- rep(0, n)
  t1[1]<-theta[1]
  lambda0 <- rep(0,n)
  lambda0[1] <- theta[2]
  lambda1 <- rep(0,n)
  lambda1[1]<-theta[3]
  beta <- rep(0,n)
  beta[1]<-theta[4]
  for(i in 2:n){
     #Sampling theta1 using Gibbs
      y0 <- sum(coal$date<t1[i-1])-1
      y1 <- 189-y0
      lambda0[i] <- rgamma(1, y0+2, 1/(t1[i-1]-t0+1/beta[i-1]))
      lambda1[i] <- rgamma(1, y1+2, 1/(t2-t1[i-1]+1/beta[i-1]))
      beta[i] <- rinvgamma(1, 4, 1+lambda0[i-1]+lambda1[i-1])
      
      
      #Metroplois-Hastings for sampling from t1
      proposal <-rnorm(1, t1[i-1], 10)
      if(proposal<t0 || proposal>t2){
        accept.prob=0
      }
      else{
        accept.prob <- min(1, exp((t1[i-1]-proposal)*(lambda0[i-1]-lambda1[i-1])*lambda0[i-1]^y0*lambda1[i-1]^y1))
      }
      u <- runif(1)
      if(u<accept.prob){
        t1[i]<-proposal
      }
      else{
        t1[i]<-t1[i-1]
      }
      
      }
  thetamat <- data.frame(t1,lambda0, lambda1, beta)
  return(thetamat)
}

simulation = MCMC(theta0,2000)
```

## A5

``` {r A5}
n = length(t(simulation[1]))

# Trace plot of t1
ggplot() +
  geom_line( aes(x = 1:n, y = t(simulation[1])) ) +
  xlab('Iterations') + ylab(expression(t[1])) + 
  ggtitle(expression(paste('Trace plot of ', t[1]))) 

# Trace plot of lambda0
ggplot()+
  geom_line( aes(x = 1:n, y = t(simulation[2])) ) +
  xlab('Iterations') + ylab(expression(lambda[0])) + 
  ggtitle(expression(paste('Trace plot of ', lambda[0])))

# Trace plot of lambda1
ggplot()+
  geom_line( aes(x = 1:n, y = t(simulation[3])) ) +
  xlab('Iterations') + ylab(expression(lambda[1])) + 
  ggtitle(expression(paste('Trace plot of ', lambda[1])))

# Trace plot of beta
ggplot()+
  geom_line( aes(x = 1:n, y = t(simulation[4])) ) +
  xlab('Iterations') + ylab(expression(beta)) + 
  ggtitle(expression(paste('Trace plot of ', beta)))
```

```{r}
par(mfrow = c(2,2))
acf(simulation[1])
acf(simulation[2])
acf(simulation[3])
acf(simulation[4])
```
